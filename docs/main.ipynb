{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Normalizer, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas, time, uuid, statistics\n",
    "import numpy as np\n",
    "import json\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2\n",
    "\n",
    "def train_model_holdout(X_train, x_test, y_train, y_test, classifier_class, **kwargs):\n",
    "    \n",
    "    classifier = classifier_class(**kwargs)\n",
    "    # Train the neural network classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    output = dict()\n",
    "    output[\"accuracy_score\"] = sklearn.metrics.accuracy_score(y_test, y_pred, normalize=True)\n",
    "    output[\"balanced_accuracy_score\"] = sklearn.metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True)\n",
    "    output[\"precision_score\"] = sklearn.metrics.precision_score(y_test, y_pred, average=\"weighted\", zero_division=0, labels=np.unique(y_pred))\n",
    "    output[\"recall_score\"] = sklearn.metrics.recall_score(y_test, y_pred, average=\"weighted\", zero_division=0, labels=np.unique(y_pred))\n",
    "    output[\"zero-one-loss\"] = sklearn.metrics.zero_one_loss(y_test, y_pred, normalize=True)\n",
    "\n",
    "    return output, classifier\n",
    "\n",
    "def train_model_cross_val(classifier_class, X, y, splits, shuffle_fold, **kwargs):\n",
    "    \n",
    "    classifier = classifier_class(**kwargs)\n",
    "\n",
    "    # Define k-fold cross-validation\n",
    "    k_fold = KFold(n_splits=splits, shuffle=shuffle_fold, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    scores = cross_val_score(classifier, X, y, cv=k_fold)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def preprocessing_convert_to_label(frame, column, label_map = None):\n",
    "\n",
    "    if label_map:\n",
    "        frame[column] = frame[column].map(label_map)\n",
    "    else:\n",
    "        label_encoder = LabelEncoder()\n",
    "        frame[column] = label_encoder.fit_transform(frame[column])\n",
    "\n",
    "\n",
    "def preprocessing_convert_to_one_hot_encoding(frame, column) -> pandas.DataFrame:\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    encoded_column = one_hot_encoder.fit_transform(frame[[column]])\n",
    "    \n",
    "    encoded_df = pandas.DataFrame(encoded_column.toarray(), columns=one_hot_encoder.get_feature_names_out([column]))\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    return pandas.concat([frame, encoded_df], axis=1).drop(column, axis=1, inplace=False)\n",
    "\n",
    "def preprocessing_apply_normalize_scaling(frame, column):\n",
    "    mean = np.mean(frame[column]) # Normalizer did not work properly, only returned array of 1's\n",
    "    sd = np.std(frame[column])\n",
    "    frame[column] = (frame[column] - mean) / sd \n",
    "\n",
    "def preprocessing_apply_minmax_scaling(frame, column):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    frame[column] = scaler.fit_transform(frame[[column]])\n",
    "\n",
    "\n",
    "def preprocessing_impute_missing_with_mode(frame: pandas.DataFrame, column: str, missingValue: str | bytes):\n",
    "    mode = statistics.mode(frame[frame[column] != missingValue][column]) \n",
    "    frame.loc[frame[column] == missingValue, column] = mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Choice] Enable/Disable Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = \"normal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = \"minmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Choice] One-Hot Encoding/Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Choice] Missing Values for nominals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute with mode (Modus im Deutschen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 'missing' to new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Choice] Dataset Selection + Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Seattle\n",
    "Report number cut completely, ocurred_time and reported_time scaling division by 2400, crime_subcategory, beat, neighborhood and precinct to label\n",
    "\n",
    "Important values: IMPUTE, LABELLING, SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_name = \"seattle\"\n",
    "\n",
    "data = loadarff(\"data\\\\seattle.arff\")\n",
    "df = pandas.DataFrame(data[0])\n",
    "y = pandas.DataFrame(df[\"Primary_Offense_Description\"])\n",
    "x = df.drop(\"Primary_Offense_Description\", axis=1)\n",
    "\n",
    "x1 = x.copy()\n",
    "y1 = y.copy()\n",
    "\n",
    "# Delete unnecessary columns\n",
    "x1.drop(\"Report_Number\", axis=1, inplace=True)\n",
    "\n",
    "# Scaling, always apply minmax if not none, because normalization makes no sense\n",
    "if SCALING is not None:\n",
    "    x1[\"Occurred_Time\"] /= 2400\n",
    "    x1[\"Reported_Time\"] /= 2400\n",
    "\n",
    "# Convert to label or one hot\n",
    "missing_values = [b\"?\", b'UNKNOWN', b'?', b'?', b\"UNKNOWN\"]\n",
    "to_label = [\"Crime_Subcategory\", \"Precinct\", \"Sector\", \"Beat\", \"Neighborhood\"]\n",
    "\n",
    "for missing_val, column in zip(missing_values, to_label):\n",
    "    if IMPUTE:\n",
    "        preprocessing_impute_missing_with_mode(x1, column, missing_val)\n",
    "\n",
    "    if LABELING:\n",
    "        preprocessing_convert_to_label(x1, column)\n",
    "    else:\n",
    "        x1 = preprocessing_convert_to_one_hot_encoding(x1, column)\n",
    "\n",
    "preprocessing_convert_to_label(y1, \"Primary_Offense_Description\")\n",
    "y1 = y1['Primary_Offense_Description'].values.ravel()\n",
    "\n",
    "# Missing Values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(x1)\n",
    "\n",
    "imputed_data = imputer.transform(x1)\n",
    "\n",
    "imputed_frame = pandas.DataFrame(imputed_data, columns=x1.columns)\n",
    "x1[\"Occurred_Time\"] = imputed_frame[\"Occurred_Time\"]\n",
    "x1[\"Reported_Time\"] = imputed_frame[\"Reported_Time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Mushrooms\n",
    "Preprocessing: cap-diameter, stem-height (mean?), stem-width (mean?) scaling; cap-shape, cap-surface, cap-color, stem-color, gill-attachment, gill-spacing, gill-color, stem-root, stem-surface, veil-type, does-bruise-or-bleed, veil-color, has-ring, ring-type, spore-print-color, habitat, season labeling/one hot. as missing values are nominal only, they are seen as an own atrribute\n",
    "\n",
    "Important values: IMPUTE, LABELLING, SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mushroom\"\n",
    "\n",
    "df = pandas.read_csv(\"data\\\\mushroom\\\\secondary_data.csv\", sep=\";\", na_values=\"nan\", keep_default_na=False)\n",
    "x = df.drop(\"class\", axis=1, inplace=False)\n",
    "y = df[\"class\"]\n",
    "\n",
    "x1 = x.copy()\n",
    "y1 = y.copy()\n",
    "\n",
    "to_label = ['cap-shape', 'cap-surface', 'cap-color', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-color' ,'stem-surface', 'veil-type', 'does-bruise-or-bleed', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season']\n",
    "for column in to_label:\n",
    "    if IMPUTE:\n",
    "        preprocessing_impute_missing_with_mode(x1, column, \"\")\n",
    "    if LABELING:\n",
    "        preprocessing_convert_to_label(x1, column)\n",
    "    else:\n",
    "        x1 = preprocessing_convert_to_one_hot_encoding(x1, column)\n",
    "\n",
    "to_scale = [\"cap-diameter\", \"stem-height\", \"stem-width\"]\n",
    "\n",
    "\n",
    "if SCALING is not None:\n",
    "    for i in to_scale:\n",
    "        if SCALING == \"normal\":\n",
    "            preprocessing_apply_normalize_scaling(x1, i)\n",
    "        elif SCALING == \"minmax\":\n",
    "            preprocessing_apply_minmax_scaling(x1, i)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y1 = label_encoder.fit_transform(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congressional Voting\n",
    "Preprocessing: Labelling all attibutes and handling missing values\n",
    "\n",
    "Important values: IMPUTE, LABELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"congress\"\n",
    "\n",
    "df = pandas.read_csv(\"data\\\\congress\\\\CongressionalVotingID.shuf.lrn.csv\", sep=\",\")\n",
    "x = df.drop(\"class\", axis=1, inplace=False).drop(\"ID\", axis=1, inplace=False)\n",
    "y = df[\"class\"]\n",
    "\n",
    "x1 = x.copy()\n",
    "y1 = y.copy()\n",
    "\n",
    "to_label = x1.columns\n",
    "\n",
    "for i in to_label:\n",
    "    if IMPUTE:\n",
    "        preprocessing_impute_missing_with_mode(x1, i, \"unknown\")\n",
    "\n",
    "    if LABELING:\n",
    "        preprocessing_convert_to_label(x1, i, {\"y\": 1, \"n\": 0, \"unknown\": 2})\n",
    "    else:\n",
    "        x1 = preprocessing_convert_to_one_hot_encoding(x1, i) # I am not sure how much one hot encoding makes sense here\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y1 = label_encoder.fit_transform(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews\n",
    "Preprocessing: Mostly scaling, no nominal values (except for target) and no missing values(?)\n",
    "\n",
    "Important values: SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"reviews\"\n",
    "\n",
    "df = pandas.read_csv(\"data\\\\reviews\\\\amazon_review_ID.shuf.lrn.csv\", sep=\",\")\n",
    "x = df.drop(\"Class\", axis=1, inplace=False).drop(\"ID\", axis=1, inplace=False)\n",
    "y = df[\"Class\"]\n",
    "x[\"Sums\"] = x.sum(axis=1)\n",
    "x1 = x.copy()\n",
    "y1 = y.copy()\n",
    "\n",
    "\n",
    "to_scale = x1.columns\n",
    "\n",
    "if SCALING is not None:\n",
    "    for i in to_scale:\n",
    "        if SCALING == \"normal\":\n",
    "            preprocessing_apply_normalize_scaling(x1, i)\n",
    "        elif SCALING == \"minmax\":\n",
    "            preprocessing_apply_minmax_scaling(x1, i)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y1 = label_encoder.fit_transform(y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### [Optional] Display Data Before and After Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "      <th>Sums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9992  V9993  V9994  V9995  \\\n",
       "0    17   4   8   8   9   4   0   2   3    5  ...      0      0      0      0   \n",
       "1    21   9   5   8   6   2  16   3  12    6  ...      0      0      0      2   \n",
       "2     9   7   6   3   8   2   9   4   4    5  ...      0      0      0      0   \n",
       "3     8   3   5   2   4   3   8   2   4    4  ...      0      0      1      0   \n",
       "4    15   8   8   4   7   8   4   7   1    3  ...      0      0      0      0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...    ...    ...    ...    ...   \n",
       "745   8   1   5   6   0   5   2   2   2    4  ...      0      0      0      1   \n",
       "746  13   7   3   4   7   4   2   3   5    2  ...      0      0      0      0   \n",
       "747  13   8   6   6  11   0  11   2   4    1  ...      1      0      0      0   \n",
       "748  14  16   7   8  11   8   9   3   7    7  ...      0      0      0      0   \n",
       "749  12  11   7  11   6   1   0   2   2    2  ...      2      0      1      0   \n",
       "\n",
       "     V9996  V9997  V9998  V9999  V10000  Sums  \n",
       "0        0      0      0      1       1  4057  \n",
       "1        2      1      0      1       0  5609  \n",
       "2        0      0      0      1       1  3204  \n",
       "3        1      0      0      0       0  3488  \n",
       "4        0      0      0      0       0  4916  \n",
       "..     ...    ...    ...    ...     ...   ...  \n",
       "745      0      0      0      1       0  3210  \n",
       "746      0      1      0      0       0  5548  \n",
       "747      0      0      1      0       0  4690  \n",
       "748      0      0      0      0       0  5698  \n",
       "749      0      0      0      0       0  4524  \n",
       "\n",
       "[750 rows x 10001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0           Shea\n",
       "1          Riley\n",
       "2        Chachra\n",
       "3        Agresti\n",
       "4          Nigam\n",
       "         ...    \n",
       "745    Calvinnme\n",
       "746         Shea\n",
       "747     Cholette\n",
       "748      Sherwin\n",
       "749       Janson\n",
       "Name: Class, Length: 750, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "      <th>Sums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.571818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.836258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.426478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.474868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.718180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.825865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.679673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.851423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.651389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1        V2    V3    V4        V5        V6        V7        V8  \\\n",
       "0    0.53125  0.210526  0.40  0.40  0.428571  0.266667  0.000000  0.142857   \n",
       "1    0.65625  0.473684  0.25  0.40  0.285714  0.133333  0.761905  0.214286   \n",
       "2    0.28125  0.368421  0.30  0.15  0.380952  0.133333  0.428571  0.285714   \n",
       "3    0.25000  0.157895  0.25  0.10  0.190476  0.200000  0.380952  0.142857   \n",
       "4    0.46875  0.421053  0.40  0.20  0.333333  0.533333  0.190476  0.500000   \n",
       "..       ...       ...   ...   ...       ...       ...       ...       ...   \n",
       "745  0.25000  0.052632  0.25  0.30  0.000000  0.333333  0.095238  0.142857   \n",
       "746  0.40625  0.368421  0.15  0.20  0.333333  0.266667  0.095238  0.214286   \n",
       "747  0.40625  0.421053  0.30  0.30  0.523810  0.000000  0.523810  0.142857   \n",
       "748  0.43750  0.842105  0.35  0.40  0.523810  0.533333  0.428571  0.214286   \n",
       "749  0.37500  0.578947  0.35  0.55  0.285714  0.066667  0.000000  0.142857   \n",
       "\n",
       "           V9       V10  ...  V9992  V9993  V9994  V9995     V9996     V9997  \\\n",
       "0    0.230769  0.277778  ...    0.0    0.0  0.000    0.0  0.000000  0.000000   \n",
       "1    0.923077  0.333333  ...    0.0    0.0  0.000    0.4  0.666667  0.333333   \n",
       "2    0.307692  0.277778  ...    0.0    0.0  0.000    0.0  0.000000  0.000000   \n",
       "3    0.307692  0.222222  ...    0.0    0.0  0.125    0.0  0.333333  0.000000   \n",
       "4    0.076923  0.166667  ...    0.0    0.0  0.000    0.0  0.000000  0.000000   \n",
       "..        ...       ...  ...    ...    ...    ...    ...       ...       ...   \n",
       "745  0.153846  0.222222  ...    0.0    0.0  0.000    0.2  0.000000  0.000000   \n",
       "746  0.384615  0.111111  ...    0.0    0.0  0.000    0.0  0.000000  0.333333   \n",
       "747  0.307692  0.055556  ...    0.2    0.0  0.000    0.0  0.000000  0.000000   \n",
       "748  0.538462  0.388889  ...    0.0    0.0  0.000    0.0  0.000000  0.000000   \n",
       "749  0.153846  0.111111  ...    0.4    0.0  0.125    0.0  0.000000  0.000000   \n",
       "\n",
       "     V9998     V9999  V10000      Sums  \n",
       "0     0.00  0.333333    0.25  0.571818  \n",
       "1     0.00  0.333333    0.00  0.836258  \n",
       "2     0.00  0.333333    0.25  0.426478  \n",
       "3     0.00  0.000000    0.00  0.474868  \n",
       "4     0.00  0.000000    0.00  0.718180  \n",
       "..     ...       ...     ...       ...  \n",
       "745   0.00  0.333333    0.00  0.427500  \n",
       "746   0.00  0.000000    0.00  0.825865  \n",
       "747   0.25  0.000000    0.00  0.679673  \n",
       "748   0.00  0.000000    0.00  0.851423  \n",
       "749   0.00  0.000000    0.00  0.651389  \n",
       "\n",
       "[750 rows x 10001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([43, 41,  9,  0, 38, 34, 15, 35,  1,  4, 46, 19,  9, 21, 38, 29, 19,\n",
       "       14, 18,  8, 11, 43, 13, 26, 39, 15, 19,  8, 17, 17, 49, 31, 20, 34,\n",
       "       17, 23,  5,  2, 44, 13, 13, 12, 29, 32, 45, 48, 39,  1, 13, 39,  1,\n",
       "       45, 38,  9, 33,  3, 10, 46,  8, 21, 10, 12, 24, 48, 48, 23, 22, 14,\n",
       "        3, 11,  2, 12,  9, 22, 44, 25, 23, 25, 49,  7, 12, 27, 14, 33, 38,\n",
       "       11,  5,  0, 16, 30, 40, 26, 34, 25, 43,  1, 43, 42,  9, 38, 33, 22,\n",
       "       14, 42, 43, 15, 46, 14,  0, 29, 41,  4,  4, 36, 43, 25, 14, 39, 40,\n",
       "        9, 28, 41, 49, 23, 10, 11, 36, 11, 10, 31,  7, 37, 45, 32, 36, 36,\n",
       "        3, 14, 39, 26, 19, 44, 11, 15, 43, 18, 44, 44,  4,  6,  6, 15, 17,\n",
       "       42, 35, 44, 45, 28, 15, 34,  6, 33, 30, 22, 49, 41, 49, 10, 31, 49,\n",
       "       24,  2, 40, 49, 49,  7, 41, 46, 13, 42, 46, 12,  3, 44, 34, 47, 28,\n",
       "       18, 13, 26,  1,  7,  5, 47, 35, 37,  9, 48, 33,  1, 23, 24, 45, 44,\n",
       "       47,  3, 24,  8, 41, 40, 43, 33,  6, 34, 24,  1,  9, 44,  6, 47,  3,\n",
       "        3, 20, 31,  8, 37,  8,  9, 36, 23, 32, 19, 44, 11, 14, 40,  6, 43,\n",
       "        5, 36, 28, 26,  8, 30, 47, 22, 16, 49, 38,  1, 17, 33, 44, 25, 35,\n",
       "       42, 22, 27, 37, 12, 21, 18,  3,  0, 48,  5, 10, 20, 27, 48,  4, 13,\n",
       "        2,  9, 12, 25, 47,  9, 32,  7, 19,  7, 35,  0, 44, 34, 40,  0,  4,\n",
       "       20, 24,  4, 22,  4, 14, 40,  9, 11,  6, 45, 22, 35, 27, 16, 24, 32,\n",
       "       13,  3, 40, 29, 43, 18, 37, 48, 16, 37,  7, 22, 19,  9, 45, 33, 49,\n",
       "        5, 22, 44, 15, 23, 27,  7, 28, 40, 44, 45, 42, 22, 11, 18, 19, 22,\n",
       "       40, 49, 38, 31,  8, 15, 38, 28, 30,  6, 39,  4, 47, 28, 19, 45, 28,\n",
       "       39, 11, 14, 24, 34, 13, 11, 22, 40, 40, 31, 42, 21, 21, 46, 40,  0,\n",
       "       24, 32, 15, 37,  3, 29,  5, 36, 31,  8, 41,  8, 20, 10, 11, 22, 23,\n",
       "       42, 14,  5,  3, 40, 44, 30, 16, 12, 30,  1, 31, 14, 11, 28, 18, 29,\n",
       "       41, 13, 39,  2, 27, 19, 25, 35, 38, 46, 20,  7, 38, 35, 13, 15, 16,\n",
       "       26, 20, 16, 49, 38, 20, 26, 27, 36,  5, 15, 37,  5,  7, 31, 25, 10,\n",
       "       28, 48, 23, 31, 16, 13, 21, 41, 15,  0,  6,  8, 40,  1, 43, 19, 14,\n",
       "        2, 30, 16,  7, 44, 27,  0, 18, 41, 46, 10, 13, 34,  4, 43, 11, 33,\n",
       "        6, 48, 30, 36,  2, 49, 20, 46,  5,  7, 10, 32, 16, 32,  1,  4, 31,\n",
       "       48,  9, 42, 20, 36, 47,  6, 37, 30, 33, 23, 17, 15, 30, 34, 32, 28,\n",
       "       18, 16, 16, 33, 49, 33, 19, 12, 44, 29, 13, 39,  3, 30, 17, 42, 35,\n",
       "       13,  4, 33, 14, 46,  6, 27,  1, 34, 10, 45, 42, 22, 11, 27, 38, 16,\n",
       "       25, 20, 26, 23, 47, 10, 18, 39, 26, 41, 47, 14, 43, 36, 42,  6, 16,\n",
       "        7, 44,  7,  2, 26, 27, 10, 30, 37, 22, 11, 10,  8, 16, 19, 23, 13,\n",
       "       19,  5,  5, 11, 30, 31, 32, 22, 39, 20,  9, 13,  9, 45,  0, 20, 43,\n",
       "       40, 23, 48, 21, 37, 27, 35, 37,  9, 12,  2, 37,  3, 43, 25, 46, 27,\n",
       "       15, 20, 22, 41, 29,  6, 23, 49, 34, 27, 38, 32, 28, 33,  9,  4, 10,\n",
       "        6,  3, 37, 12, 34,  0, 31, 25,  2, 20, 24, 28, 49, 24, 47,  8,  0,\n",
       "       30, 36, 29, 17,  0, 34, 16,  3, 12, 33, 36, 21, 16, 21,  5, 40, 37,\n",
       "       34, 46,  0, 18, 31, 40, 42, 33, 14, 10, 41, 49,  4, 26,  3, 30, 21,\n",
       "       17, 11, 19, 34, 36, 10,  2, 15,  2, 19,  0,  4, 47, 29, 44, 21, 48,\n",
       "       33,  4, 18, 46, 12, 32, 32, 41, 21, 13,  4, 17, 38, 12, 41, 12, 21,\n",
       "       24,  6, 32, 13, 17, 28, 16, 25, 42,  5, 40, 20, 49, 37, 21,  0, 33,\n",
       "       48, 47, 35,  8, 28,  9, 21, 49, 45, 35, 46, 46,  7, 24,  8, 43, 12,\n",
       "       44, 23])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x)\n",
    "display(y)\n",
    "display(x1)\n",
    "display(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Choice + Config] Classifier + Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classifier = MLPClassifier\n",
    "name_prefix = \"mlp\"\n",
    "kwargs = {\n",
    "    \"hidden_layer_sizes\": (100,), # array-like of shape (n_layers - 2,), default=(100,)\n",
    "    \"activation\": \"logistic\", # {\"identity\", \"logistic\", \"tanh\", \"relu\"}, default=\"relu\"\n",
    "    \"alpha\": 0.0001, # float, default=0.0001\n",
    "    \"batch_size\": \"auto\", # int, default=\"auto\"\n",
    "    \"solver\": \"adam\", # {\"lbfgs\", \"sgd\", \"adam\"}, default=\"adam\"\n",
    "    \"learning_rate\": \"constant\", # {\"constant\", \"invscaling\", \"adaptive\"}, default=\"constant\"; only matters if solver=\"sgd\"\n",
    "    \"learning_rate_init\": 0.001, # float, default=0.001; only when solver=\"sgd\" or \"adam\"\n",
    "    \"power_t\": 0.5, # float, default=0.5, when solver=\"sgd\"\n",
    "    \"max_iter\": 100, # int, default=200\n",
    "    \"shuffle\": True, # bool, default=True\n",
    "    \"random_state\": RANDOM_STATE, # int, RandomState instance, default=None\n",
    "    \"tol\": 0.0001, # float, default=1e-4\n",
    "    \"verbose\": True, # bool, default=False\n",
    "    \"warm_start\": False, # bool, default=False\n",
    "    \"momentum\": 0.9, # float, default=0.9; only when solver=\"sgd\"\n",
    "    \"nesterovs_momentum\": True, # bool, default=True; only when momentum > 0 and solver=\"sgd\"\n",
    "    \"early_stopping\": False, # bool, default=False; only solver=\"sgd\" or \"adam\"\n",
    "    \"validation_fraction\": 0.1, # float, default=0.1\n",
    "    \"beta_1\": 0.9, # float, default=0.9; only solver=\"adam\"\n",
    "    \"beta_2\": 0.999, # float, default=0.999; only solver=\"adam\"\n",
    "    \"epsilon\": 1e-08, # float, default=1e-8; only solver=\"adam\"\n",
    "    \"n_iter_no_change\": 10, # int, default=10; only solver=\"sgd\" or \"adam\"\n",
    "    \"max_fun\": 15000, # int, default=15000; only solver=\"lbfgs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classifier = KNeighborsClassifier\n",
    "name_prefix = \"knn\"\n",
    "kwargs = {\n",
    "    \"n_neighbors\": 5,  # int, default=5\n",
    "    \"weights\": \"distance\",  # {\"uniform\", \"distance\"}, callable, or None, default=\"uniform\"\n",
    "    \"algorithm\": \"ball_tree\",  # {\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"}, default=\"auto\"\n",
    "    \"leaf_size\": 1,  # int, default=30, for kd and ball\n",
    "    \"p\": 2,  # float, default=2\n",
    "    \"metric\": \"minkowski\",  # str or callable, default=\"minkowski\"\n",
    "    \"metric_params\": None,  # dict, default=None\n",
    "    \"n_jobs\": None  # int, default=None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classifier = RandomForestClassifier\n",
    "name_prefix = \"rf\"\n",
    "kwargs = {\n",
    "    \"n_estimators\": 30,  # int, default=100\n",
    "    \"criterion\": \"log_loss\",  # \"gini\", \"entropy\", \"log_loss\" defaukt=gini\n",
    "    \"max_depth\": 50,  # int, default=None CAUTION: default value None is dangerous for the pc\n",
    "    \"min_samples_split\": 2,  # int or float, default=2\n",
    "    \"min_samples_leaf\": 1,  # int or float, default=1\n",
    "    \"min_weight_fraction_leaf\": 0.0,  # float, default=0.0\n",
    "    \"max_features\": \"sqrt\",  # \"sqrt\", \"log2\", None, int, or float, default=\"sqrt\"\n",
    "    \"max_leaf_nodes\": None,  # int, default=None\n",
    "    \"min_impurity_decrease\": 0.0,  # float, default=0.0\n",
    "    \"bootstrap\": True,  # bool, default=True\n",
    "    \"oob_score\": False,  # bool or callable, default=False\n",
    "    \"n_jobs\": -1,  # int, default=None\n",
    "    \"random_state\": RANDOM_STATE,  # int, RandomState instance, or None, default=None\n",
    "    \"verbose\": 0,  # int, default=0\n",
    "    \"warm_start\": False,  # bool, default=False\n",
    "    \"class_weight\": None,  # {\"balanced\", \"balanced_subsample\"}, dict or list of dicts, default=None\n",
    "    \"ccp_alpha\": 0.0,  # non-negative float, default=0.0\n",
    "    \"max_samples\": None,  # int or float, default=None\n",
    "    \"monotonic_cst\": None  # array-like of int of shape (n_features), default=None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9772727272727273,\n",
       " 'balanced_accuracy_score': 0.9615384615384617,\n",
       " 'precision_score': 0.9784688995215312,\n",
       " 'recall_score': 0.9772727272727273,\n",
       " 'zero-one-loss': 0.022727272727272707}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "start = time.time()\n",
    "score1, model1 = train_model_holdout(x1_train, x1_test, y1_train, y1_test, selected_classifier, **kwargs)\n",
    "duration1 = time.time() - start\n",
    "modelid1 = str(uuid.uuid4().hex)\n",
    "modelid1 = dataset_name + modelid1\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97727273, 0.97727273, 0.93181818, 0.97674419, 0.95348837]),\n",
       " 0.9633192389006343)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = 5\n",
    "start = time.time()\n",
    "score2 = train_model_cross_val(selected_classifier, x1, y1, splits, shuffle_fold=True, **kwargs)\n",
    "duration2 = time.time() - start\n",
    "score2, np.mean(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"reports\\\\{name_prefix}_{dataset_name}.json\", \"r\") as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "if len(contents) > 2:\n",
    "    contents[-2] = contents[-2].replace(\"\\n\", \",\\n\")\n",
    "\n",
    "def add_quotes(val):\n",
    "    return '\"' + val + '\"'\n",
    "\n",
    "contents.insert(-1, f'\\t{\"{\"}\"id\": \"{modelid1}\", \"Settings\": {json.dumps(kwargs)}, \"Scaling\": {add_quotes(SCALING) if SCALING else SCALING}, \"Labeling\": \"{LABELING}\", \"Impute\": \"{IMPUTE}\", \"Holdout\": {\"{\"}\"Duration\": {duration1}, \"Score\": {json.dumps(score1)}{\"}\"}, \"CV\": {\"{\"}\"Duration\": {duration2}, \"Accuracy\": {str(score2).replace(\" \", \",\")}, \"Mean\": {np.mean(score2)}{\"}\"}{\"}\"}\\r')\n",
    "\n",
    "\n",
    "with open(f\"reports\\\\{name_prefix}_{dataset_name}.json\", \"w\") as f:\n",
    "    contents = \"\".join(contents)\n",
    "    f.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\rf\\\\congress2f78414fb1cb4e7b8353d34eb6cf28cb.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model1, f\"models\\\\{name_prefix}\\\\{modelid1}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
